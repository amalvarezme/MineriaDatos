{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install joblib\n","execution_count":null,"outputs":[]},{"metadata":{"id":"plLadWOYYoWy"},"cell_type":"markdown","source":"# Analítica de datos - ejemplo de clase lfw_people - comparación distintos métodos de clasificación - Ejecución sobre Google Colaboratory"},{"metadata":{"id":"Xfr51WJ_YoWz"},"cell_type":"markdown","source":"## Lectura base de datos y partición conjunto de entrenamiento y conjunto de evaluación\n\nNota: conjunto de evaluación no se utiliza en NINGUNA etapa de entrenamiento "},{"metadata":{"id":"G6HAFfHzm8S7"},"cell_type":"markdown","source":"# Se declaran las funciones principales a utilizar sobre el cuaderno\n# también se puede generar un archivo .py desde su Google drive (ver celda principal de carga de datos en este cuaderno)"},{"metadata":{"id":"khSouH2Zk2kK","trusted":true},"cell_type":"code","source":"import os\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\nfrom sklearn.base import  BaseEstimator, TransformerMixin\nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA \nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#%% Analisis exploratorio basico - base de datos housing\ndef pre_exploratorio(Xtrain_pre,ytrain_pre,path_img,col_sal,w,h,Np=None):\n    #exploratorio basico -> Normalizar + reduccion de dimensionalidad\n    normalizar = StandardScaler()\n    #escoger aleatoriamente puntos para evitar costo computacional - analisis inicial\n    if Np == None: Np = len(Xtrain_pre.index)\n    \n    ind = np.random.randint(0,len(Xtrain_pre.index),Np) #escoger subconjunto de datos\n    \n    Xz = normalizar.fit_transform(Xtrain_pre.iloc[ind,:])\n    yc = ytrain_pre[ind].reshape(-1)\n    \n    #reduccion de dimension con pca y tsne\n    red_pca = PCA()\n    #perplexity = np.round(0.75*np.sqrt(Np))\n    #red_tsne = TSNE(n_components=2,perplexity = perplexity, n_iter = 250,verbose = 10)\n        \n    Xred_pca = pd.DataFrame(red_pca.fit_transform(Xz))\n    #Xred_tsne = pd.DataFrame(red_tsne.fit_transform(Xz))\n  \n    #Relevancia por variabilidad\n    var_ret = 0.95\n    rel_vec,Mv,ind_rel = rel_pca(red_pca,var_ret)\n    \n    #graficar\n    sval = 30\n    #pca 2D\n    Xred_pca.plot(kind=\"scatter\",x=0,y=1,\n               c = yc, s=sval, label = col_sal,\n              colormap = \"jet\",colorbar=True, sharex=False)    \n    plt.title('PCA 2D')\n    plt.xlabel('Componente principal 1')\n    plt.ylabel('Componente principal 2')\n    #save_fig(path_img,\"red_PCA2D\")\n    plt.show()\n    \n    #relevancia pca 2D     \n    plt.imshow(rel_vec.reshape(w,h),cmap='jet')\n    plt.ylabel('Relevancia PCA - eigenfaces')\n    plt.title('RELEVANCIA PCA - eigenfaces, var_ret=%.2f' % (var_ret))\n    plt.colorbar()\n    #save_fig(path_img,\"relevancia_PCA_eigenface\")\n    plt.show()\n    #tsne 2D\n    #Xred_tsne.plot(kind=\"scatter\",x=0,y=1,\n    #           c = yc, s = sval, label = col_sal,\n    #          colormap = \"jet\",colorbar=True, sharex=False)    \n    #plt.title('t-sne 2D - Perp.=%.2f' % perplexity)\n    #plt.xlabel('Embebimiento - Dim. 1')\n    #plt.ylabel('Embebimiento - Dim. 2')\n    #save_fig(path_img,\"tsne_2D\")\n    #plt.show()\n    \n    return True\n#%% relevancia por variabilidad con pca\ndef rel_pca(red,var_exp):\n    Mv = np.min(np.where(np.cumsum(red.explained_variance_ratio_)\n                         >var_exp))\n    M,P = red.components_.shape\n    #print(P,M)\n    rel_vec = np.zeros((P))\n    for i in range(Mv):\n        #print(i)\n        rel_vec += abs(red.explained_variance_ratio_[i]*red.components_[i,:])\n    \n    rel_vec = rel_vec/sum(rel_vec)\n    rel_vec = rel_vec - min(rel_vec)\n    rel_vec = rel_vec/max(rel_vec)\n    \n    ind_rel = rel_vec.argsort()[::-1]\n    return rel_vec, Mv,ind_rel\n\n#%%  guardar figuras\n#from google.colab import files\ndef save_fig(path_img,fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(path_img, fig_id + \".\" + fig_extension)\n    print(\"Guardando...\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)\n    files.download(path) \n    \nimport seaborn as sns\n\ndef roc_auc_mc(roc_auc,fpr,tpr,n_classes,title,path_img):   \n    lw = 2\n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(n_classes):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n    # Finally average it and compute AUC\n    mean_tpr /= n_classes\n\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n    # Plot all ROC curves\n    plt.figure(figsize=(6,6))\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n\n    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n             label='macro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"macro\"]),\n             color='navy', linestyle=':', linewidth=4)\n\n    #colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n    colors = sns.color_palette(None, n_classes)\n    for i, color in zip(range(n_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                 label='AUC_class_{0} (area = {1:0.2f})'\n                 ''.format(i, roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(title)\n    plt.legend(loc=\"best\")#,bbox_to_anchor=(1.4, 0.75))\n\n    #save_fig(path_img,title)\n    plt.show()\n\n    \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nfrom itertools import cycle\n#matriz confusión = #[[TN FP][FN TP]]\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') #clasificador aleatorio\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n\n    \n# Compute ROC curve and ROC area for each class\ndef roc_multiclass(ytrue,yscore):\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    n_classes = ytrue.shape[1]\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(ytrue[:, i], yscore[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ytrue.ravel(), yscore.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    return roc_auc, fpr, tpr, n_classes\n    #fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = 100*cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    \n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.1f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n","execution_count":null,"outputs":[]},{"metadata":{"id":"BR6wFAw_YoW0","outputId":"acda41b2-8470-42eb-99a4-fe94d2400635","trusted":true},"cell_type":"code","source":"#Paso 1: Lectura\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#para acceder a archivos desde google drive en google colaboratory\n#acceso a google drive\n#from pydrive.auth import GoogleAuth\n#from pydrive.drive import GoogleDrive\n#from google.colab import auth\n#from oauth2client.client import GoogleCredentials\n#\n#auth.authenticate_user()\n#gauth = GoogleAuth()\n#gauth.credentials = GoogleCredentials.get_application_default()\n#drive = GoogleDrive(gauth)\n#\n#file_id = '1TDxi5fWoS1zraYYsk0IfoVB0XQt--HJw' #copiar nombre nombre del link de compartir despues de ID\n#downloaded = drive.CreateFile({'id': file_id})\n#downloaded.GetContentFile('funciones_people.py') \n#from funciones_people import pre_exploratorio, save_fig, plot_confusion_matrix, roc_multiclass, roc_auc_mc\n\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.pipeline import Pipeline\n#base de datos\nfrom sklearn.datasets import fetch_lfw_people\n#https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html\n\n%matplotlib inline\n#descargar base de datos\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n\n#ejemplo imagen en base de datos\n#print('Dimensiones base de datos: \\n',lfw_people.images.shape)\n#plt.imshow(lfw_people.images[30,:,:],cmap='gray')\n\n#print('Clases base de datos: \\n',lfw_people['target_names'])\n#print(lfw_people.images[30,:,:])","execution_count":null,"outputs":[]},{"metadata":{"id":"BEH-EPjqYoW3","outputId":"1eefb0bf-d2d5-4f9c-b0e5-6057d59b7b22","trusted":true},"cell_type":"code","source":"# datos tipo pandas\nXdata = pd.DataFrame(lfw_people.data)/255\ny = lfw_people.target\nprint('Dimensiones tipo pandas: ',Xdata.shape)\nplt.imshow(np.array(Xdata.iloc[0,:]).reshape(lfw_people.images.shape[1],lfw_people.images.shape[2]),cmap='gray')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"gYFELAfgYoW5","outputId":"b3b04cb6-ca57-4d39-dd5f-669c82569ebe","trusted":true},"cell_type":"code","source":"#Paso 2: Particion entrenamiento y validacion\n# Tamaño Xtrain 70%, Tamaño Xtest 30%\nXtrain, Xtest, ytrain,ytest = train_test_split(Xdata,y,test_size=0.3) #fijar en 0.3 para entrenar -- 0.95 para demostrar funcionalidad del código\n\nXtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"7V3np2mqYoW7","outputId":"d6be4dae-5c0e-4dab-ff94-9e1820f8f28a","trusted":true},"cell_type":"code","source":"#%% Paso 3 : Analisis exploratorio\n#preproceso entrada  y salida para analisis exploratorio\nimg_path = '' #para guardar from google.colab import files plt.savefig(\"abc.png\") files.download(\"abc.png\") \npre_exploratorio(Xtrain,ytrain,img_path,'People',lfw_people.images.shape[1],lfw_people.images.shape[2])","execution_count":null,"outputs":[]},{"metadata":{"id":"wv8rKILFYoW9","outputId":"2457bc40-f314-4ec0-8379-91e78501eff6","trusted":true},"cell_type":"code","source":"#%% Paso 4 : Escoger modelo por gridsearchCV utilizando pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n#from sklearn.externals import joblib #https://joblib.readthedocs.io/en/latest/\nimport joblib\n\nsteps=[[('rep',  PCA()),\n        ('cla', LogisticRegression())],\n       [('rep',  PCA()),\n        ('cla', SGDClassifier())],\n        [('cla', SVC())]\n       #[('rep',  PCA()),\n       # ('cla', SVC())]\n      ]\nparameters = [{\n              'rep__n_components' : [0.8,0.9],              \n              'cla__C': [0.5,1],\n              },\n              {\n              'rep__n_components' : [0.8,0.9],              \n              'cla__alpha': [0.0001,0.001],\n              },\n              {\n             #'rep__n_components' : [0.8,0.9],              \n             'cla__C': [0.1,1,100,500,1e3],\n             'cla__gamma': [0.01, 0.1, 1,10, 100,1e3]     \n             }\n             ]\n\nlabel_models = ['PCA_Logistic','PCA_SGD', 'SVCrbf']\n\nbest_model = []\nfilename = ''#'resultados/people_comp'\nfor i in range(len(steps)):\n    print('modelo %d/%d' % (i+1,len(steps)))\n    grid_search = GridSearchCV(Pipeline(steps[i]), parameters[i], n_jobs=-1,cv=5,\n                                scoring='balanced_accuracy',verbose=10)\n    grid_search.fit(Xtrain, ytrain)\n    #print(grid_search.cv_results_)\n    #mejor modelo entrenado\n    best_model += [grid_search.best_estimator_]\n    joblib.dump(best_model,filename+\".pkl\")\n\nprint('Mejores modelos:\\n')\nbest_model","execution_count":null,"outputs":[]},{"metadata":{"id":"_xF1Fg68YoW_"},"cell_type":"markdown","source":"# Calcular rendimiento en cojunto de test"},{"metadata":{"id":"3ncCiTNdYoW_","outputId":"2d8df242-2746-4be4-fee1-11352e5aa4dc","trusted":true},"cell_type":"code","source":"#%% Paso 5: evaluar sobre Xtest\nmy_model_loaded = joblib.load(filename+\".pkl\")\npath_img = ''\nfor i in range(len(my_model_loaded)):\n    print('Evaluando modelo %d/%d' % (i+1,len(my_model_loaded)))\n\n    ytest_e = my_model_loaded[i].predict(Xtest)\n    acc = accuracy_score(ytest,ytest_e)\n     \n    plot_confusion_matrix(\n                          ytest, ytest_e, \n                          classes=lfw_people.target_names,\n                          normalize=True,\n                          title='ACC = %.1f %%' % (100*acc)\n                          )\n    plt.autoscale()\n    #save_fig(path_img,label_models[i])                      \n    plt.show()\n    \n    cr = classification_report(\n                               ytest, ytest_e, \n                               labels=range(lfw_people.target_names.shape[0]),\n                               target_names=lfw_people.target_names\n                               )                          \n    #support = #muestras en la clase estudiada\n    print(cr)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-QH4I3f-YoXB"},"cell_type":"markdown","source":"## Curva ROC multiclase - sobre conjunto de test"},{"metadata":{"id":"OVw3yxoDYoXC","outputId":"59731a08-d807-42fd-ffaa-9b911b760e40","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import label_binarize\n\nytrain_b = label_binarize(ytrain, classes=range(lfw_people.target_names.shape[0]))\nytest_b = label_binarize(ytest, classes=range(lfw_people.target_names.shape[0]))\n\nfor i in range(len(my_model_loaded)):\n    print('Evaluando ROC modelo %d/%d' % (i+1,len(my_model_loaded)))\n    ytest_score = my_model_loaded[i].decision_function(Xtest) #debe calcularse la funcion de decision o el posterior de la probabilidad\n    roc_auc, fpr, tpr, n_classes = roc_multiclass(ytest_b,ytest_score)\n    roc_auc_mc(roc_auc,fpr,tpr,n_classes,'ROC curve ' + label_models[i],path_img)\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"JNv020cRYoXD","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}